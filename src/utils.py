"""
================================================================================
UTILS.PY - Fun√ß√µes Utilit√°rias para An√°lise de Texto e Machine Learning
================================================================================

Este arquivo cont√©m todas as fun√ß√µes auxiliares utilizadas no projeto de 
classifica√ß√£o de textos com explicabilidade (LIME).

ESTRUTURA DO ARQUIVO:
1. Importa√ß√µes de Bibliotecas
2. Fun√ß√µes de An√°lise de Texto
3. Fun√ß√µes de Pr√©-processamento de Texto
4. Fun√ß√µes de Vetoriza√ß√£o
5. Fun√ß√µes de Avalia√ß√£o de Modelos
6. Fun√ß√µes de Treino de Modelos
7. Fun√ß√µes de Visualiza√ß√£o e An√°lise
8. Fun√ß√µes de Similaridade

Autor: Miguel Maur√≠cio Ant√≥nio
√öltima atualiza√ß√£o: Dezembro 2025
================================================================================
"""

# ============================================================================
# 1. IMPORTA√á√ïES DE BIBLIOTECAS
# ============================================================================

# Bibliotecas gerais
import pandas as pd
import numpy as np
import re
import string
from tqdm import tqdm
import matplotlib.pyplot as plt

# Bibliotecas de pr√©-processamento de texto
import emoji 
import nltk
from nltk.corpus import stopwords
import spacy 

# Bibliotecas de Machine Learning
from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer
from sklearn.linear_model import LogisticRegression, SGDClassifier
from sklearn.naive_bayes import BernoulliNB, ComplementNB
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.svm import SVC, LinearSVC
from sklearn.neural_network import MLPClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score as sk_accuracy, \
                            precision_score as sk_precision, \
                            recall_score as sk_recall, \
                            roc_auc_score as sk_roc_auc, \
                            classification_report
import seaborn as sns

# Bibliotecas de Interpretabilidade
from lime.lime_text import LimeTextExplainer



# ============================================================================
# 2. FUN√á√ïES DE AN√ÅLISE DE TEXTO
# ============================================================================

def avgSizeWords(text):
    """
    Calcula o tamanho m√©dio das palavras em um texto.
    
    Esta fun√ß√£o divide o texto em palavras e calcula a m√©dia do n√∫mero de 
    caracteres por palavra.
    
    Args:
        text (str): Texto a ser analisado
        
    Returns:
        float: M√©dia do n√∫mero de caracteres por palavra. Retorna 0 se o texto estiver vazio.
        
    Exemplo:
        >>> avgSizeWords("ol√° mundo teste")
        4.33  # (3 + 5 + 5) / 3
    """
    list_string = text.split()
    if not list_string:
        return 0
    chars = np.array([len(s) for s in list_string])
    return chars.mean()


def trucateText(text):
    """
    Trunca um texto para um m√°ximo de 100 palavras.
    
    Esta fun√ß√£o √© √∫til para limitar o tamanho de textos muito longos,
    mantendo apenas as primeiras 100 palavras.
    
    Args:
        text (str): Texto a ser truncado
        
    Returns:
        str: Texto original (se tiver ‚â§100 palavras) ou texto truncado (primeiras 100 palavras)
        
    Exemplo:
        >>> trucateText("palavra " * 150)  # Texto com 150 palavras
        "palavra palavra ... palavra"  # Apenas 100 palavras
    """
    words = text.split()
    if len(words) <= 100:
        return text
    else:
        words = words[0:100]
        text = ' '.join(words)
        return text


# ============================================================================
# 3. FUN√á√ïES DE PR√â-PROCESSAMENTO DE TEXTO
# ============================================================================

# ----------------------------------------------------------------------------
# 3.1 Processamento de Emojis e Pontua√ß√£o
# ----------------------------------------------------------------------------

# Listas de emojis e pontua√ß√£o para processamento
emojis_list = list(emoji.EMOJI_DATA.keys())  # Lista de todos os emojis conhecidos
emojis_list += ['\n']  # Adiciona quebra de linha √† lista
punct = list(string.punctuation) + ['\n']  # Lista de pontua√ß√£o + quebra de linha
emojis_punct = emojis_list + punct  # Lista combinada


def processEmojisPunctuation(text, remove_punct=False, remove_emoji=False):
    """
    Processa emojis e pontua√ß√£o em um texto.
    
    Esta fun√ß√£o pode tanto remover quanto separar (adicionar espa√ßos) emojis e pontua√ß√£o.
    Separar √© √∫til para que cada emoji/pontua√ß√£o seja tratado como um token individual.
    
    Args:
        text (str): Texto a ser processado
        remove_punct (bool): Se True, remove pontua√ß√£o. Se False, adiciona espa√ßos ao redor
        remove_emoji (bool): Se True, remove emojis. Se False, adiciona espa√ßos ao redor
        
    Returns:
        str: Texto processado com emojis/pontua√ß√£o removidos ou separados
        
    Exemplo:
        >>> processEmojisPunctuation("Ol√°!üòäComo vai?", remove_punct=False, remove_emoji=False)
        "Ol√° ! üòä Como vai ?"
        >>> processEmojisPunctuation("Ol√°!üòäComo vai?", remove_punct=True, remove_emoji=True)
        "Ol√° Como vai"
    """
    chars = set(text)
    for c in chars:
        # Processar pontua√ß√£o
        if remove_punct:
            if c in punct:
                text = text.replace(c, ' ')  # Remove substituindo por espa√ßo
        else:
            if c in punct:
                text = text.replace(c, ' ' + c + ' ')  # Separa com espa√ßos

        # Processar emojis
        if remove_emoji:
            if c in emojis_list:
                text = text.replace(c, ' ')  # Remove substituindo por espa√ßo
        else:
            if c in emojis_list:
                text = text.replace(c, ' ' + c + ' ')  # Separa com espa√ßos

    # Remove espa√ßos m√∫ltiplos
    text = re.sub(' +', ' ', text)
    return text


# ----------------------------------------------------------------------------
# 3.2 Remo√ß√£o de Stopwords (Palavras Irrelevantes)
# ----------------------------------------------------------------------------

# Lista base de stopwords em portugu√™s do NLTK
stop_words = list(stopwords.words('portuguese'))

# Stopwords adicionais espec√≠ficas do dom√≠nio (redes sociais, abrevia√ß√µes, etc.)
new_stopwords = ['a√≠','pra','v√£o','vou','onde','l√°','aqui',
                    't√°','pode','pois','so','deu','agora','todo',
                    'nao','ja','vc', 'bom', 'ai','ta', 'voce', 'alguem', 'ne', 'pq',
                    'cara','to','mim','la','vcs','tbm', 'tudo','mst', 'ip', 've', 
                    'td', 'msg', 'abs', 'ft', 
                    'rs', 'sqn', 'cmg', 
                    '03', '27', 
                    'http', 'https', 'www',
                    'tocantim']

# Combina as duas listas
stop_words = stop_words + new_stopwords

# Adiciona espa√ßos ao redor de cada stopword para evitar remo√ß√µes parciais
# Exemplo: ' de ' em vez de 'de' para n√£o remover 'de' de 'desde'
final_stop_words = []
for sw in stop_words:
    sw = ' '+ sw + ' '
    final_stop_words.append(sw)


def removeStopwords(text):
    """
    Remove stopwords (palavras irrelevantes) de um texto.
    
    Stopwords s√£o palavras muito comuns que geralmente n√£o contribuem para o 
    significado do texto (ex: 'de', 'para', 'com', 'o', 'a', etc.).
    
    Args:
        text (str): Texto do qual remover stopwords
        
    Returns:
        str: Texto sem stopwords
        
    Exemplo:
        >>> removeStopwords(" eu vou para a casa ")
        " eu casa "  # 'vou', 'para', 'a' foram removidas
    """
    for sw in final_stop_words:
        text = text.replace(sw,' ')
    # Remove espa√ßos m√∫ltiplos
    text = re.sub(' +',' ',text)
    return text


# ----------------------------------------------------------------------------
# 3.3 Lematiza√ß√£o (Redu√ß√£o de Palavras √† Forma Base)
# ----------------------------------------------------------------------------

# Carrega o modelo de linguagem em portugu√™s do spaCy
nlp = spacy.load('pt_core_news_sm')


def lemmatization(text):
    """
    Aplica lematiza√ß√£o ao texto.
    
    Lematiza√ß√£o reduz palavras √† sua forma base (lema). Por exemplo:
    - "correndo", "correu", "correr" ‚Üí "correr"
    - "gatos" ‚Üí "gato"
    
    Isso ajuda a reduzir a dimensionalidade e agrupar palavras relacionadas.
    
    Args:
        text (str): Texto a ser lematizado
        
    Returns:
        str: Texto com palavras na forma lematizada
        
    Exemplo:
        >>> lemmatization("Os gatos estavam correndo rapidamente")
        "o gato estar correr rapidamente"
    """
    doc = nlp(text)
    lemmatized_tokens = []
    for token in doc:
        # Mant√©m pontua√ß√£o e espa√ßos como est√£o
        if token.is_punct or token.is_space:
             lemmatized_tokens.append(token.text)
        else:
             # Substitui pela forma lematizada
             lemmatized_tokens.append(token.lemma_)
    return " ".join(lemmatized_tokens)


# ----------------------------------------------------------------------------
# 3.4 Processamento de URLs
# ----------------------------------------------------------------------------

# VERS√ÉO ANTIGA (comentada): Extra√≠a apenas o dom√≠nio da URL
'''def domainUrl(text):
    if 'http' in text:
        re_url = '[^\s]*https*://[^\s]*'
        matches = re.findall(re_url, text, flags=re.IGNORECASE)
        for m in matches:
            domain = m.split('//')
            domain = domain[1].split('/')[0]
            text = re.sub(re_url, domain, text, 1)
        return text
    else:
        return text'''


def domainUrl(text):
    """
    Remove URLs de um texto.
    
    Esta fun√ß√£o identifica e remove todas as URLs (http, https) do texto,
    substituindo-as por espa√ßos.
    
    Args:
        text (str): Texto contendo URLs
        
    Returns:
        str: Texto sem URLs
        
    Exemplo:
        >>> domainUrl("Veja isso https://exemplo.com/artigo aqui")
        "Veja isso aqui"
    """
    if 'http' in text:
        re_url = '[^\s]*https*://[^\s]*'  # Regex para identificar URLs
        matches = re.findall(re_url, text, flags=re.IGNORECASE)
        for m in matches:
            text = text.replace(m, ' ')  # Remove a URL
        text = re.sub(' +', ' ', text).strip()  # Remove espa√ßos m√∫ltiplos
        return text
    else:
        return text


# ----------------------------------------------------------------------------
# 3.5 Processamento de Express√µes Espec√≠ficas
# ----------------------------------------------------------------------------

def processLoL(text):
    """
    Normaliza express√µes de riso em portugu√™s (kkk, kkkk, etc.).
    
    Em portugu√™s, 'kkk' √© usado para expressar riso. Esta fun√ß√£o normaliza
    todas as varia√ß√µes (kkk, kkkk, kkkkk, etc.) para apenas 'kkk'.
    
    Args:
        text (str): Texto contendo express√µes de riso
        
    Returns:
        str: Texto com express√µes de riso normalizadas
        
    Exemplo:
        >>> processLoL("Isso √© engra√ßado kkkkkkk muito bom kkkk")
        "Isso √© engra√ßado kkk muito bom kkk"
    """
    re_kkk = 'kkk*'  # Regex para capturar kkk com qualquer quantidade de k's
    t = re.sub(re_kkk, "kkk", text, flags=re.IGNORECASE)
    return t


def firstSentence(text):
    """
    Extrai a primeira frase de um texto.
    
    Divide o texto por pontua√ß√£o de fim de frase (.; ! ? ou quebra de linha)
    e retorna a primeira frase encontrada.
    
    Args:
        text (str): Texto completo
        
    Returns:
        str: Primeira frase do texto
        
    Exemplo:
        >>> firstSentence("Primeira frase. Segunda frase! Terceira?")
        "Primeira frase"
    """
    list_s = re.split('; |\. |\! |\? |\n',text)
    for s in list_s:
        if s is not None:
            return s


# ----------------------------------------------------------------------------
# 3.6 Corre√ß√£o Manual de Palavras
# ----------------------------------------------------------------------------

# Dicion√°rio de corre√ß√µes manuais para palavras escritas incorretamente
correction_map = {
    'olher': 'olhar',      # Erro comum de digita√ß√£o
    'erraddad': 'errado'   # Erro comum de digita√ß√£o
}


def manual_correction(text, mapping):
    """
    Aplica corre√ß√µes manuais de palavras mal escritas.
    
    Usa um dicion√°rio de mapeamento para corrigir palavras espec√≠ficas que
    s√£o frequentemente escritas incorretamente no dataset.
    
    Args:
        text (str): Texto a ser corrigido
        mapping (dict): Dicion√°rio {palavra_errada: palavra_correta}
        
    Returns:
        str: Texto com corre√ß√µes aplicadas
        
    Exemplo:
        >>> manual_correction("vou olher isso", {'olher': 'olhar'})
        "vou olhar isso"
    """
    for wrong, right in mapping.items():
        # \b garante que apenas palavras completas sejam substitu√≠das
        text = re.sub(r'\b' + re.escape(wrong) + r'\b', right, text)
    return text


# ----------------------------------------------------------------------------
# 3.7 Fun√ß√£o Principal de Pr√©-processamento
# ----------------------------------------------------------------------------

def preprocess(text, semi=False, rpunct=False, remoji=False, sentence=False):
    """
    Aplica todas as etapas de pr√©-processamento a um texto.
    
    Esta √© a fun√ß√£o principal que orquestra todas as etapas de pr√©-processamento
    na ordem correta. Pode ser configurada para aplicar diferentes n√≠veis de
    processamento.
    
    Args:
        text (str): Texto a ser processado
        semi (bool): Se True, retorna ap√≥s processamento parcial (sem stopwords/lematiza√ß√£o)
        rpunct (bool): Se True, remove pontua√ß√£o (sen√£o apenas separa)
        remoji (bool): Se True, remove emojis (sen√£o apenas separa)
        sentence (bool): Se True, processa apenas a primeira frase
        
    Returns:
        str: Texto pr√©-processado
        
    Pipeline de processamento:
        1. Extrai primeira frase (se sentence=True)
        2. Converte para min√∫sculas
        3. Aplica corre√ß√µes manuais
        4. Remove URLs
        5. Normaliza express√µes de riso (kkk)
        6. Processa emojis e pontua√ß√£o
        7. Remove stopwords (se semi=False)
        8. Aplica lematiza√ß√£o (se semi=False)
        
    Exemplo:
        >>> preprocess("Ol√°! Como vai? https://site.com kkkkk üòä")
        "ol√° ir kkk üòä"  # (simplificado)
    """
    # 1. Extrai primeira frase se necess√°rio
    if sentence:
        text = firstSentence(text)
    
    # 2. Normaliza√ß√£o b√°sica
    text = text.lower().strip()
    
    # 3. Corre√ß√µes manuais
    text = manual_correction(text, correction_map)
    
    # 4. Remove URLs
    text = domainUrl(text)
    
    # 5. Normaliza express√µes de riso
    text = processLoL(text)
    
    # 6. Processa emojis e pontua√ß√£o
    text = processEmojisPunctuation(text, remove_punct=rpunct, remove_emoji=remoji)
    
    # 7. Se semi=True, retorna aqui (processamento parcial)
    if semi:
        return text
    
    # 8. Remove stopwords
    text = removeStopwords(text)
    
    # 9. Aplica lematiza√ß√£o
    text = lemmatization(text)
    
    return text


# ============================================================================
# 4. FUN√á√ïES DE VETORIZA√á√ÉO
# ============================================================================

def defineVectorizing(experiment):
    """
    Define e configura o vetorizador apropriado baseado no nome do experimento.
    
    Esta fun√ß√£o cria um vetorizador (Bag-of-Words ou TF-IDF) com configura√ß√µes
    espec√≠ficas de n-gramas baseado no nome do experimento.
    
    Args:
        experiment (str): Nome do experimento no formato 'vectorizer-ngram[-max_features]'
                         Exemplos: 'bow-unigram', 'tfidf-unigram_bigram-max_features'
        
    Returns:
        CountVectorizer ou TfidfVectorizer: Vetorizador configurado
        
    Configura√ß√µes do experimento:
        - Vetorizador: 'bow' (Bag of Words) ou 'tfidf' (TF-IDF)
        - N-gramas: 'unigram' (1,1), 'unigram_bigram' (1,2), 'unigram_bigram_trigram' (1,3)
        - max_features: Se presente no nome, limita a 5000 features
        - min_df: N-gramas que aparecem menos de 5 vezes s√£o ignorados
        
    Exemplo:
        >>> vec = defineVectorizing('tfidf-unigram_bigram-max_features')
        >>> # Retorna TfidfVectorizer com n-gramas (1,2) e max 5000 features
    """
    max_feat = None
    
    # Define o n√∫mero m√°ximo de features se especificado no experimento
    if 'max_features' in experiment:
        max_feat = 5000
    
    # Divide o nome do experimento em partes
    exp_parts = experiment.split('-')
    vec = exp_parts[0]  # Tipo de vetorizador (bow ou tfidf)
    ngram = exp_parts[1]  # Tipo de n-grama
    
    # Configura o range de n-gramas
    if ngram == 'unigram':
        ng = (1,1)  # Apenas palavras individuais
    elif ngram == 'unigram_bigram':
        ng = (1,2)  # Palavras individuais e pares de palavras
    elif ngram == 'unigram_bigram_trigram':
        ng = (1,3)  # Palavras individuais, pares e trios

    # Frequ√™ncia m√≠nima: n-gramas que aparecem menos de 5 vezes n√£o s√£o contados
    MIN_FREQUENCY = 5

    # Cria o vetorizador apropriado
    if vec == 'bow':
        # Bag of Words: conta presen√ßa/aus√™ncia de palavras (binary=True)
        vectorizer = CountVectorizer(
            max_features=max_feat,      # Limite de features (ou None)
            binary=True,                 # Apenas presen√ßa/aus√™ncia (n√£o frequ√™ncia)
            ngram_range=ng,              # Range de n-gramas
            lowercase=False,             # N√£o converte para min√∫sculas (j√° feito no preprocess)
            token_pattern=r'\b\w\w+\b',  # Padr√£o: palavras com 2+ caracteres
            min_df=MIN_FREQUENCY         # Frequ√™ncia m√≠nima
        )
    elif vec == 'tfidf':
        # TF-IDF: pondera pela frequ√™ncia e raridade das palavras
        vectorizer = TfidfVectorizer(
            max_features=max_feat,       # Limite de features (ou None)
            ngram_range=ng,              # Range de n-gramas
            lowercase=False,             # N√£o converte para min√∫sculas (j√° feito no preprocess)
            token_pattern=r'\b\w\w+\b',  # Padr√£o: palavras com 2+ caracteres
            min_df=MIN_FREQUENCY         # Frequ√™ncia m√≠nima
        )

    return vectorizer


def vectorizing(vectorizer, texts_train, texts_test):
    """
    Aplica vetoriza√ß√£o aos textos de treino e teste.
    
    Esta fun√ß√£o treina o vetorizador no conjunto de treino e transforma
    tanto o treino quanto o teste em vetores num√©ricos.
    
    Args:
        vectorizer: Vetorizador j√° configurado (CountVectorizer ou TfidfVectorizer)
        texts_train (list): Lista de textos de treino (j√° pr√©-processados)
        texts_test (list): Lista de textos de teste (j√° pr√©-processados)
        
    Returns:
        tuple: (X_train, X_test) - Matrizes esparsas com os vetores de features
        
    Processo:
        1. Aprende o vocabul√°rio do conjunto de treino
        2. Transforma textos de treino em vetores usando esse vocabul√°rio
        3. Transforma textos de teste em vetores usando o mesmo vocabul√°rio
        
    Nota:
        √â crucial que o vetorizador seja treinado APENAS no conjunto de treino
        para evitar data leakage.
        
    Exemplo:
        >>> vec = defineVectorizing('tfidf-unigram')
        >>> X_train, X_test = vectorizing(vec, train_texts, test_texts)
        Train: (8000, 5000)  # 8000 amostras, 5000 features
        Test: (2000, 5000)   # 2000 amostras, mesmas 5000 features
    """
    # Aprende o vocabul√°rio apenas do conjunto de treino
    vectorizer.fit(texts_train)
    
    # Transforma os textos em vetores usando o vocabul√°rio aprendido
    X_train = vectorizer.transform(texts_train)
    X_test = vectorizer.transform(texts_test)
    
    # Imprime as dimens√µes para verifica√ß√£o
    print('Train:', X_train.shape)
    print('Test:', X_test.shape)
    
    return X_train, X_test


# ============================================================================
# 5. FUN√á√ïES DE AVALIA√á√ÉO DE MODELOS
# ============================================================================

def getTestMetrics(y_true, y_pred, y_prob=None, full_metrics=False, class_names=None):
    """
    Calcula m√©tricas de avalia√ß√£o para um modelo de classifica√ß√£o.
    
    Esta fun√ß√£o calcula diversas m√©tricas de desempenho e gera um relat√≥rio
    de classifica√ß√£o completo.
    
    Args:
        y_true (array): Labels verdadeiros
        y_pred (array): Predi√ß√µes do modelo
        y_prob (array, opcional): Probabilidades preditas (para calcular AUC)
        full_metrics (bool): Se True, imprime todas as m√©tricas
        class_names (list, opcional): Nomes das classes para o relat√≥rio
        
    Returns:
        tuple: (accuracy, precision, precision_neg, recall, recall_neg, 
                f1, f1_neg, roc_auc, report_str)
        
    M√©tricas calculadas:
        - Accuracy: Propor√ß√£o de predi√ß√µes corretas
        - Precision (weighted): Precis√£o m√©dia ponderada por classe
        - Recall (weighted): Recall m√©dio ponderado por classe
        - F1 (weighted): F1-score m√©dio ponderado por classe
        - ROC-AUC: √Årea sob a curva ROC (se y_prob fornecido)
        - Classification Report: Relat√≥rio detalhado por classe
    """
    # Calcula m√©tricas principais
    acc = sk_accuracy(y_true, y_pred)
    precision = sk_precision(y_true, y_pred, average='weighted')
    recall = sk_recall(y_true, y_pred, average='weighted')
    
    # Calcula F1 manualmente para evitar problemas de arredondamento
    epsilon = 1e-7  # Evita divis√£o por zero
    f1 = 2 * (precision * recall) / (precision + recall + epsilon) if (precision + recall) > 0 else 0

    # Tenta calcular ROC-AUC (pode falhar se y_prob n√£o fornecido)
    try:
        roc_auc = sk_roc_auc(y_true, y_prob, multi_class='ovr')
    except Exception:
        roc_auc = np.nan

    # M√©tricas para classe negativa (n√£o utilizadas atualmente)
    precision_neg = recall_neg = f1_neg = np.nan
    
    # Gera o relat√≥rio de classifica√ß√£o como string
    report_str = classification_report(y_true, y_pred, target_names=class_names, output_dict=False)
    
    # Imprime m√©tricas se solicitado
    if full_metrics:
        print(f"## üìä M√©tricas de Desempenho (Weighted) ##")
        print(f"Accuracy: {acc:.3f}")
        print(f"Precision (W): {precision:.3f}")
        print(f"Recall (W): {recall:.3f}")
        print(f"F1 (W): {f1:.3f}")
        print(f"AUC: {roc_auc:.3f}")
        print("\n---")
        print("## üìã Classification Report ##")
        print(report_str)

    return acc, precision, precision_neg, recall, recall_neg, f1, f1_neg, roc_auc, report_str


def save_reports_to_txt(models_results, filename='classifications_reports.txt'):
    """
    Salva os relat√≥rios de classifica√ß√£o de m√∫ltiplos modelos em um arquivo .txt.
    
    Esta fun√ß√£o √© √∫til para documentar e comparar os resultados de diferentes
    modelos em um formato leg√≠vel.
    
    Args:
        models_results (dict): Dicion√°rio onde:
                              - chave: nome do modelo (str)
                              - valor: tupla (modelo_treinado, metricas)
        filename (str): Nome do arquivo de sa√≠da (padr√£o: 'classifications_reports.txt')
        
    Formato do arquivo:
        RELAT√ìRIOS DE CLASSIFICA√á√ÉO DOS MODELOS
        ==================================================
        
        === Modelo: Logistic Regression ===
        [relat√≥rio de classifica√ß√£o]
        --------------------------------------------------
        
        === Modelo: Random Forest ===
        [relat√≥rio de classifica√ß√£o]
        --------------------------------------------------
    """
    with open(filename, 'w', encoding='utf-8') as f:
        f.write("RELAT√ìRIOS DE CLASSIFICA√á√ÉO DOS MODELOS\n")
        f.write("="*50 + "\n\n")
        
        for model_name, (model_obj, metrics) in models_results.items():
            # O report_str √© o √∫ltimo item da tupla de m√©tricas
            report_str = metrics[-1] 
            
            f.write(f"=== Modelo: {model_name} ===\n")
            f.write(report_str)
            f.write("\n" + "-"*50 + "\n\n")
            
    print(f"Todos os relat√≥rios foram salvos em '{filename}'")


# ============================================================================
# 6. FUN√á√ïES DE VISUALIZA√á√ÉO E AN√ÅLISE
# ============================================================================

# Importa√ß√µes adicionais para visualiza√ß√£o (j√° importadas no topo, mas listadas aqui para clareza)
import matplotlib.pyplot as plt
import pandas as pd
import seaborn as sns
from sklearn.metrics import classification_report


def plot_bias_analysis(models_results, X_test, y_test, class_labels=['Real', 'Fake']):
    """
    Cria um gr√°fico de an√°lise de vi√©s (bias) entre classes para m√∫ltiplos modelos.
    
    Esta fun√ß√£o visualiza a discrep√¢ncia no F1-score entre duas classes para cada
    modelo, ajudando a identificar quais modelos t√™m vi√©s em favor de uma classe.
    
    Args:
        models_results (dict): Dicion√°rio onde:
                              - chave: nome do modelo (str)
                              - valor: tupla (modelo_treinado, metricas)
        X_test: Features do conjunto de teste
        y_test: Labels verdadeiros do conjunto de teste
        class_labels (list): Nomes das duas classes (padr√£o: ['Real', 'Fake'])
        
    Returns:
        DataFrame: Tabela com F1-scores por classe e gap para cada modelo
        
    Visualiza√ß√£o:
        - Eixo Y: Modelos (ordenados por menor gap)
        - Eixo X: F1-score
        - Pontos: F1-score de cada classe
        - Linha: Conecta os dois F1-scores, mostrando o gap
        - Texto: Valor da diferen√ßa (gap) entre as classes
        
    Interpreta√ß√£o:
        - Gap pequeno: Modelo balanceado entre as classes
        - Gap grande: Modelo com vi√©s em favor de uma classe
        
    Exemplo:
        >>> df = plot_bias_analysis(models_results, X_test, y_test)
        # Exibe gr√°fico e retorna DataFrame com os dados
    """
    data = []
    
    # 1. Extrai F1-scores de cada modelo para cada classe
    for model_name, (model, _) in models_results.items():
        # Faz predi√ß√µes
        y_pred = model.predict(X_test)
        
        # Gera relat√≥rio de classifica√ß√£o como dicion√°rio
        report = classification_report(y_test, y_pred, output_dict=True)
        
        # Extrai apenas as chaves das classes (ignora 'accuracy', 'macro avg', etc.)
        keys = [k for k in report.keys() if k not in ['accuracy', 'macro avg', 'weighted avg']]
        
        # Extrai F1-scores das duas classes
        f1_c0 = report[keys[0]]['f1-score']
        f1_c1 = report[keys[1]]['f1-score']
        
        # Armazena os dados
        data.append({
            'Model': model_name.replace('\n', ' '),  # Remove quebras de linha do nome
            f'{class_labels[0]}': f1_c0,
            f'{class_labels[1]}': f1_c1,
            'Gap': abs(f1_c0 - f1_c1)  # Diferen√ßa absoluta entre as classes
        })
    
    # 2. Cria DataFrame com os dados
    df = pd.DataFrame(data)
    
    # 3. Ordena por gap (menor gap = modelo mais balanceado aparece em cima)
    df = df.sort_values('Gap', ascending=True)

    # 4. Cria o gr√°fico
    plt.figure(figsize=(10, 8))
    
    # Desenha linhas horizontais conectando os F1-scores das duas classes
    plt.hlines(y=df['Model'], xmin=df[class_labels[0]], xmax=df[class_labels[1]], 
               color='grey', alpha=0.4, linewidth=3)
    
    # Desenha pontos para cada classe
    plt.scatter(df[class_labels[0]], df['Model'], color='#1f77b4', alpha=1, s=100, label=class_labels[0])
    plt.scatter(df[class_labels[1]], df['Model'], color='#ff7f0e', alpha=1, s=100, label=class_labels[1])
    
    # 5. Adiciona texto mostrando o gap para cada modelo
    for _, row in df.iterrows():
        # Calcula ponto m√©dio entre os dois F1-scores
        mid_point = (row[class_labels[0]] + row[class_labels[1]]) / 2
        
        # Adiciona texto com o valor do gap
        plt.text(x=mid_point, y=row['Model'], s=f"diff: {row['Gap']:.2f}", 
                 color='#333333', fontsize=9, ha='center', va='bottom', fontweight='bold')

    # 6. Configura√ß√µes de estilo do gr√°fico
    plt.title('Bias Analysis: F1-Score Discrepancy Between Classes', fontsize=14, fontweight='bold')
    plt.xlabel('F1-Score', fontsize=12)
    plt.grid(axis='x', linestyle='--', alpha=0.6)
    plt.legend(title='Class', loc='lower right')
    plt.margins(y=0.1)  # Adiciona margem vertical para melhor visualiza√ß√£o

    plt.tight_layout()
    plt.show()
    
    return df



# ============================================================================
# 7. FUN√á√ïES DE TREINO E AVALIA√á√ÉO DE MODELOS
# ============================================================================

def lr_eval(X_train, y_train, X_test, y_test):
    """
    Treina e avalia um modelo de Regress√£o Log√≠stica.
    
    Regress√£o Log√≠stica √© um modelo linear simples e interpret√°vel, ideal como
    baseline. Funciona bem para problemas linearmente separ√°veis.
    
    Args:
        X_train: Features de treino (matriz esparsa ou densa)
        y_train: Labels de treino
        X_test: Features de teste
        y_test: Labels de teste
        
    Returns:
        tuple: (modelo_treinado, metricas)
        
    Caracter√≠sticas do modelo:
        - Linear e interpret√°vel
        - R√°pido para treinar
        - Bom baseline para compara√ß√£o
    """
    print('=== Logistic Regression ===')
    logreg = LogisticRegression().fit(X_train, y_train)
    y_pred = logreg.predict(X_test)
    y_prob = logreg.predict_proba(X_test)[:, 1]
    metrics = getTestMetrics(y_test, y_pred, y_prob, full_metrics=True)
    return logreg, metrics


def nb_eval(X_train, y_train, X_test, y_test, experiment):
    """
    Treina e avalia um modelo Naive Bayes.
    
    Escolhe automaticamente entre BernoulliNB (para Bag-of-Words) e 
    ComplementNB (para TF-IDF) baseado no tipo de vetoriza√ß√£o.
    
    Args:
        X_train: Features de treino
        y_train: Labels de treino
        X_test: Features de teste
        y_test: Labels de teste
        experiment: Tupla/lista contendo informa√ß√µes do experimento (primeiro elemento indica vetoriza√ß√£o)
        
    Returns:
        tuple: (modelo_treinado, metricas)
        
    Caracter√≠sticas:
        - BernoulliNB: Para features bin√°rias (Bag-of-Words)
        - ComplementNB: Para features cont√≠nuas (TF-IDF), lida melhor com desbalanceamento
        - Muito r√°pido para treinar
        - Assume independ√™ncia entre features (simplifica√ß√£o forte)
    """
    if 'bow' in experiment[0]:
        print('=== Bernoulli Naive-Bayes ===')
        nb = BernoulliNB().fit(X_train, y_train)
    elif 'tfidf' in experiment[0]:
        print('=== Complement Naive-Bayes ===')
        nb = ComplementNB().fit(X_train, y_train)
    else:
        nb = BernoulliNB().fit(X_train, y_train)
    y_pred = nb.predict(X_test)
    y_prob = nb.predict_proba(X_test)[:, 1]
    metrics = getTestMetrics(y_test, y_pred, y_prob, full_metrics=True)
    return nb, metrics


def lsvm_eval(X_train, y_train, X_test, y_test):
    """
    Treina e avalia uma SVM Linear (Support Vector Machine).
    
    SVM Linear encontra o hiperplano que melhor separa as classes com a
    maior margem poss√≠vel.
    
    Args:
        X_train: Features de treino
        y_train: Labels de treino
        X_test: Features de teste
        y_test: Labels de teste
        
    Returns:
        tuple: (modelo_treinado, metricas)
        
    Caracter√≠sticas:
        - Eficiente para alta dimensionalidade (muitas features)
        - dual=False: Usa formula√ß√£o primal (mais r√°pido para muitas features)
        - N√£o fornece probabilidades diretamente
        - Robusto e geralmente tem bom desempenho em texto
    """
    print('=== Linear Support Vector Machine ===')
    svm = LinearSVC(dual=False).fit(X_train, y_train)
    y_pred = svm.predict(X_test)
    metrics = getTestMetrics(y_test, y_pred, full_metrics=True)
    return svm, metrics


def sgd_eval(X_train, y_train, X_test, y_test):
    """
    Treina e avalia uma SVM Linear com treinamento SGD (Stochastic Gradient Descent).
    
    Similar √† LinearSVC, mas usa otimiza√ß√£o por gradiente descendente estoc√°stico,
    o que pode ser mais r√°pido para datasets muito grandes.
    
    Args:
        X_train: Features de treino
        y_train: Labels de treino
        X_test: Features de teste
        y_test: Labels de teste
        
    Returns:
        tuple: (modelo_treinado, metricas)
        
    Caracter√≠sticas:
        - Escal√°vel para datasets grandes
        - Treinamento incremental (pode processar dados em batches)
        - Converg√™ncia pode ser menos est√°vel que LinearSVC
    """
    print('=== Linear SVM with SGD training ===')
    sgd = SGDClassifier().fit(X_train, y_train)
    y_pred = sgd.predict(X_test)
    metrics = getTestMetrics(y_test, y_pred, full_metrics=True)
    return sgd, metrics


def svm_eval(X_train, y_train, X_test, y_test):
    """
    Treina e avalia uma SVM com kernel RBF (Radial Basis Function).
    
    SVM com kernel RBF pode capturar rela√ß√µes n√£o-lineares entre features,
    mas √© computacionalmente mais custosa.
    
    Args:
        X_train: Features de treino
        y_train: Labels de treino
        X_test: Features de teste
        y_test: Labels de teste
        
    Returns:
        tuple: (modelo_treinado, metricas)
        
    Caracter√≠sticas:
        - Pode capturar padr√µes n√£o-lineares
        - probability=True: Habilita estima√ß√£o de probabilidades
        - Mais lento que SVM linear
        - Pode ter overfitting se n√£o bem regularizado
    """
    print('=== SVM with RBF kernel ===')
    svc = SVC(probability=True).fit(X_train, y_train)
    y_pred = svc.predict(X_test)
    y_prob = svc.predict_proba(X_test)[:, 1]
    metrics = getTestMetrics(y_test, y_pred, y_prob, full_metrics=True)
    return svc, metrics


def knn_eval(X_train, y_train, X_test, y_test):
    """
    Treina e avalia um classificador K-Nearest Neighbors (KNN).
    
    KNN classifica baseado nas k amostras de treino mais pr√≥ximas.
    √â um m√©todo n√£o-param√©trico e lazy (n√£o treina, apenas memoriza).
    
    Args:
        X_train: Features de treino
        y_train: Labels de treino
        X_test: Features de teste
        y_test: Labels de teste
        
    Returns:
        tuple: (modelo_treinado, metricas)
        
    Caracter√≠sticas:
        - weights='distance': Vizinhos mais pr√≥ximos t√™m mais peso
        - n_jobs=-1: Usa todos os cores dispon√≠veis
        - Lento para predi√ß√£o em datasets grandes
        - Sens√≠vel √† escala das features e √† dimensionalidade
    """
    print('=== KNN ===')
    knn = KNeighborsClassifier(weights='distance', n_jobs=-1).fit(X_train, y_train)
    y_pred = knn.predict(X_test)
    y_prob = knn.predict_proba(X_test)[:, 1]
    metrics = getTestMetrics(y_test, y_pred, y_prob, full_metrics=True)
    return knn, metrics


def rf_eval(X_train, y_train, X_test, y_test):
    """
    Treina e avalia um classificador Random Forest.
    
    Random Forest √© um ensemble de √°rvores de decis√£o que vota para
    fazer a predi√ß√£o final. Robusto e geralmente tem bom desempenho.
    
    Args:
        X_train: Features de treino
        y_train: Labels de treino
        X_test: Features de teste
        y_test: Labels de teste
        
    Returns:
        tuple: (modelo_treinado, metricas)
        
    Caracter√≠sticas:
        - Ensemble de √°rvores de decis√£o
        - n_jobs=-1: Paraleliza√ß√£o para treino mais r√°pido
        - Robusto a overfitting (comparado a uma √∫nica √°rvore)
        - Pode capturar intera√ß√µes n√£o-lineares
        - Fornece import√¢ncia de features
    """
    print('=== Random Forest ===')
    rf = RandomForestClassifier(n_jobs=-1).fit(X_train, y_train)
    y_pred = rf.predict(X_test)
    y_prob = rf.predict_proba(X_test)[:, 1]
    metrics = getTestMetrics(y_test, y_pred, y_prob, full_metrics=True)
    return rf, metrics


def gb_eval(X_train, y_train, X_test, y_test):
    """
    Treina e avalia um classificador Gradient Boosting.
    
    Gradient Boosting constr√≥i √°rvores sequencialmente, onde cada nova
    √°rvore corrige os erros das anteriores.
    
    Args:
        X_train: Features de treino
        y_train: Labels de treino
        X_test: Features de teste
        y_test: Labels de teste
        
    Returns:
        tuple: (modelo_treinado, metricas)
        
    Caracter√≠sticas:
        - n_estimators=200: Usa 200 √°rvores
        - Geralmente melhor desempenho que Random Forest
        - Mais propenso a overfitting que Random Forest
        - Treinamento sequencial (n√£o paraleliz√°vel)
        - Mais lento para treinar
    """
    print('=== Gradient Boosting ===')
    gb = GradientBoostingClassifier(n_estimators=200).fit(X_train, y_train)
    y_pred = gb.predict(X_test)
    y_prob = gb.predict_proba(X_test)[:, 1]
    metrics = getTestMetrics(y_test, y_pred, y_prob, full_metrics=True)
    return gb, metrics


def mlp_eval(X_train, y_train, X_test, y_test):
    """
    Treina e avalia um Multilayer Perceptron (Rede Neural).
    
    MLP √© uma rede neural feedforward que pode aprender representa√ß√µes
    complexas e n√£o-lineares dos dados.
    
    Args:
        X_train: Features de treino
        y_train: Labels de treino
        X_test: Features de teste
        y_test: Labels de teste
        
    Returns:
        tuple: (modelo_treinado, metricas)
        
    Caracter√≠sticas:
        - verbose=True: Mostra progresso do treinamento
        - early_stopping=True: Para quando valida√ß√£o n√£o melhora
        - batch_size=64: Processa 64 amostras por vez
        - n_iter_no_change=5: Para ap√≥s 5 √©pocas sem melhoria
        - tol=1e-3: Toler√¢ncia para crit√©rio de parada
        - Pode capturar padr√µes muito complexos
        - Requer mais dados e tuning que modelos mais simples
    """
    print('=== Multilayer Perceptron ===')
    mlp = MLPClassifier(
        verbose=True, early_stopping=True,
        batch_size=64, n_iter_no_change=5, tol=1e-3
    ).fit(X_train, y_train)
    y_pred = mlp.predict(X_test)
    y_prob = mlp.predict_proba(X_test)[:, 1]
    metrics = getTestMetrics(y_test, y_pred, y_prob, full_metrics=True)
    return mlp, metrics


def model_eval(model, X_train, y_train, X_test, y_test, experiment=None):
    """
    Fun√ß√£o dispatcher que chama a fun√ß√£o de avalia√ß√£o apropriada para cada modelo.
    
    Esta fun√ß√£o facilita o treinamento de diferentes modelos usando uma interface
    unificada, selecionando automaticamente a fun√ß√£o correta baseada no nome do modelo.
    
    Args:
        model (str): C√≥digo do modelo a treinar. Op√ß√µes:
                    - 'lr': Logistic Regression
                    - 'nb': Naive Bayes
                    - 'lsvm': Linear SVM
                    - 'sgd': SGD Classifier
                    - 'svm': SVM com kernel RBF
                    - 'knn': K-Nearest Neighbors
                    - 'rf': Random Forest
                    - 'gb': Gradient Boosting
                    - 'mlp': Multilayer Perceptron
        X_train: Features de treino
        y_train: Labels de treino
        X_test: Features de teste
        y_test: Labels de teste
        experiment (opcional): Informa√ß√µes do experimento (necess√°rio para Naive Bayes)
        
    Returns:
        tuple: (modelo_treinado, metricas)
        
    Raises:
        ValueError: Se o c√≥digo do modelo n√£o for reconhecido
        
    Exemplo:
        >>> model, metrics = model_eval('rf', X_train, y_train, X_test, y_test)
        === Random Forest ===
        ## üìä M√©tricas de Desempenho (Weighted) ##
        ...
    """
    if model == 'lr':
        return lr_eval(X_train, y_train, X_test, y_test)
    elif model == 'nb':
        return nb_eval(X_train, y_train, X_test, y_test, experiment)
    elif model == 'lsvm':
        return lsvm_eval(X_train, y_train, X_test, y_test)
    elif model == 'sgd':
        return sgd_eval(X_train, y_train, X_test, y_test)
    elif model == 'svm':
        return svm_eval(X_train, y_train, X_test, y_test)
    elif model == 'knn':
        return knn_eval(X_train, y_train, X_test, y_test)
    elif model == 'rf':
        return rf_eval(X_train, y_train, X_test, y_test)
    elif model == 'gb':
        return gb_eval(X_train, y_train, X_test, y_test)
    elif model == 'mlp':
        return mlp_eval(X_train, y_train, X_test, y_test)
    else:
        raise ValueError(f"Model '{model}' unknown.")
    


# ============================================================================
# 8. FUN√á√ïES DE SIMILARIDADE E COMPARA√á√ÉO
# ============================================================================

def calculate_jaccard(set_a, set_b):
    """
    Calcula o √≠ndice de similaridade de Jaccard entre dois conjuntos.
    
    O √≠ndice de Jaccard mede a similaridade entre dois conjuntos calculando
    a raz√£o entre a interse√ß√£o e a uni√£o dos conjuntos.
    
    Args:
        set_a: Primeiro conjunto (ou lista que ser√° convertida em conjunto)
        set_b: Segundo conjunto (ou lista que ser√° convertida em conjunto)
        
    Returns:
        float: √çndice de Jaccard entre 0.0 (completamente diferentes) e 
               1.0 (id√™nticos)
               
    F√≥rmula:
        Jaccard = |A ‚à© B| / |A ‚à™ B|
        
    Interpreta√ß√£o:
        - 0.0: Conjuntos completamente disjuntos (sem elementos em comum)
        - 0.5: 50% de similaridade
        - 1.0: Conjuntos id√™nticos
        
    Exemplo:
        >>> calculate_jaccard([1, 2, 3], [2, 3, 4])
        0.5  # Interse√ß√£o: {2, 3}, Uni√£o: {1, 2, 3, 4}
        >>> calculate_jaccard(['a', 'b'], ['a', 'b'])
        1.0  # Conjuntos id√™nticos
    """
    # Converte para set se necess√°rio
    if not isinstance(set_a, set): 
        set_a = set(set_a)
    if not isinstance(set_b, set): 
        set_b = set(set_b)
    
    # Calcula tamanho da interse√ß√£o e uni√£o
    intersection = len(set_a.intersection(set_b))
    union = len(set_a.union(set_b))
    
    # Evita divis√£o por zero
    if union == 0:
        return 0.0
    
    return intersection / union


def plot_models_metrics(models_results, save_path):
    """
    Cria um gr√°fico de barras comparando m√©tricas de m√∫ltiplos modelos.
    
    Esta fun√ß√£o gera uma visualiza√ß√£o lado a lado das principais m√©tricas
    (Accuracy, Precision, Recall, F1-Score) para todos os modelos treinados.
    
    Args:
        models_results (dict): Dicion√°rio onde:
                              - chave: nome do modelo (str)
                              - valor: tupla (modelo_treinado, metricas)
        save_path (str): Caminho para salvar o gr√°fico (padr√£o: 'model_comparison.png')
                        Se None, n√£o salva o gr√°fico
        
    Returns:
        tuple: (fig, ax, df) - Figura matplotlib, eixos e DataFrame com os dados
        
    Visualiza√ß√£o:
        - Eixo X: Modelos
        - Eixo Y: Score (0.0 a 1.0)
        - Barras agrupadas: Uma para cada m√©trica
        - Cores: Paleta de verdes para as diferentes m√©tricas
        
    Exemplo:
        >>> fig, ax, df = plot_models_metrics(models_results)
        Plot saved as 'model_comparison.png'
        
        Metrics table:
                    Model  Accuracy  Precision  Recall  F1-Score
        Logistic Regression     0.85       0.84    0.85      0.84
               Random Forest     0.88       0.87    0.88      0.87
        ...
    """
    # 1. Extrai dados das m√©tricas de cada modelo
    model_names = []
    accuracies = []
    precisions = []
    recalls = []
    f1_scores = []
    
    for name, (model, metrics) in models_results.items():
        model_names.append(name)
        accuracies.append(metrics[0])   # accuracy
        precisions.append(metrics[1])   # precision
        recalls.append(metrics[3])      # recall
        f1_scores.append(metrics[5])    # f1
    
    # 2. Cria DataFrame com os dados
    df = pd.DataFrame({
        'Model': model_names,
        'Accuracy': accuracies,
        'Precision': precisions,
        'Recall': recalls,
        'F1-Score': f1_scores
    })
    
    # 3. Configura√ß√µes do gr√°fico
    fig, ax = plt.subplots(figsize=(14, 7))
    
    # Define posi√ß√µes das barras
    x = np.arange(len(df['Model']))
    width = 0.2  # Largura de cada barra
    
    # Paleta de cores (tons de verde)
    colors = ['#90EE90', '#66CDAA', '#3CB371', '#2E8B57']
    
    # 4. Cria as barras agrupadas para cada m√©trica
    metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score']
    for i, (metric, color) in enumerate(zip(metrics, colors)):
        # Calcula offset para posicionar barras lado a lado
        offset = width * (i - 1.5)
        ax.bar(x + offset, df[metric], width, label=metric, color=color, 
               edgecolor='black', linewidth=0.7, alpha=0.9)
    
    # 5. Configura√ß√µes de estilo
    ax.set_xlabel('Models', fontsize=13, fontweight='bold')
    ax.set_ylabel('Score', fontsize=13, fontweight='bold')
    ax.set_title('Model Performance Comparison', fontsize=15, fontweight='bold', pad=20)
    ax.set_xticks(x)
    ax.set_xticklabels(df['Model'], fontsize=10)
    ax.set_ylim(0.6, 0.69)  # Ajuste conforme necess√°rio para seus dados
    ax.grid(axis='y', alpha=0.3, linestyle='--', linewidth=0.5)
    ax.set_axisbelow(True)  # Grid atr√°s das barras
    ax.legend(loc='upper left', fontsize=11, framealpha=0.9, ncol=4)
    
    plt.tight_layout()
    
    # 6. Salva o gr√°fico se caminho fornecido
    if save_path:
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        print(f"Plot saved as '{save_path}'")
    
    plt.show()
    
    # 7. Imprime tabela de m√©tricas
    print("\nMetrics table:")
    print(df.to_string(index=False))
    
    return fig, ax, df






import torch
import numpy as np
import pandas as pd
import Levenshtein
from bert_score import score as bert_score
from evaluate import load
from tqdm import tqdm

# ==========================================
# FUN√á√ïES AUXILIARES DE M√âTRICAS
# ==========================================

def jaccard_similarity(str1, str2):
    a = set(str1.split())
    b = set(str2.split())
    if not a and not b: return 1.0
    return len(a & b) / len(a | b)

def calculate_perplexity(texts, model_id='gpt2'):
    """Calcula a fluidez do texto. Requer modelo de linguagem externo."""
    perplexity_metric = load("perplexity", module_type="metric")
    results = perplexity_metric.compute(model_id=model_id, add_start_token=False, predictions=texts)
    return results['mean_perplexity']

# ==========================================
# PIPELINE DE AVALIA√á√ÉO DE XAI
# ==========================================

def evaluate_xai_counterfactuals(df_eval, ptt5_model, ptt5_tokenizer, classifier, vectorizer):
    """
    df_eval: DataFrame com ['original_text', 'target_code']
    classifier: O seu modelo original (Random Forest/MLP)
    vectorizer: O TF-IDF vectorizer usado no treino do classificador
    """
    results = []
    generated_texts = []
    
    print("A gerar contrafactuais e a calcular m√©tricas...")
    
    for _, row in tqdm(df_eval.iterrows(), total=len(df_eval)):
        orig_text = row['original_text']
        code = row['target_code'] # ex: [negation]
        
        # 1. GERAR CONTRAFACTUAL COM PTT5
        input_text = f"gerar contrafactual {code}: {orig_text}"
        inputs = ptt5_tokenizer(input_text, return_tensors="pt", truncation=True, max_length=128).to(ptt5_model.device)
        
        with torch.no_grad():
            outputs = ptt5_model.generate(inputs.input_ids, max_length=128, num_beams=5)
        gen_text = ptt5_tokenizer.decode(outputs[0], skip_special_tokens=True)
        generated_texts.append(gen_text)

        # 2. M√âTRICAS LINGU√çSTICAS
        dist = Levenshtein.distance(orig_text, gen_text)
        jaccard = jaccard_similarity(orig_text, gen_text)
        
        # 3. M√âTRICAS DE CLASSIFICA√á√ÉO (FLIP RATE & PROB SHIFT)
        # Transformar textos para o formato do classificador (TF-IDF)
        orig_vec = vectorizer.transform([orig_text])
        gen_vec = vectorizer.transform([gen_text])
        
        # Predi√ß√µes e Probabilidades
        orig_prob = classifier.predict_proba(orig_vec)[0]
        gen_prob = classifier.predict_proba(gen_vec)[0]
        
        orig_label = np.argmax(orig_prob)
        gen_label = np.argmax(gen_prob)
        
        # Flip ocorreu se a classe mudou
        flip = 1 if orig_label != gen_label else 0
        
        # Shift: Diferen√ßa na confian√ßa da classe original
        prob_shift = orig_prob[orig_label] - gen_prob[orig_label]
        
        results.append({
            'orig': orig_text,
            'gen': gen_text,
            'flip': flip,
            'prob_shift': prob_shift,
            'levenshtein': dist,
            'jaccard': jaccard
        })

    # 4. M√âTRICAS AGREGADAS (BERTScore e Perplexity)
    print("A calcular BERTScore...")
    P, R, F1 = bert_score(generated_texts, [r['orig'] for r in results], lang="pt", verbose=False)
    
    print("A calcular Perplexity...")
    # Nota: gpt2 √© base, para PT idealmente seria um modelo PT, mas gpt2 serve de proxy
    avg_ppl = calculate_perplexity(generated_texts) 

    # FINALIZAR RESULTADOS
    df_res = pd.DataFrame(results)
    
    metrics_summary = {
        "Flip Rate": df_res['flip'].mean(),
        "Avg Prob Shift": df_res['prob_shift'].mean(),
        "Avg Levenshtein": df_res['levenshtein'].mean(),
        "Avg Jaccard": df_res['jaccard'].mean(),
        "BERTScore F1": F1.mean().item(),
        "Perplexity": avg_ppl
    }
    
    return metrics_summary, df_res


# ============================================================================
# FIM DO ARQUIVO UTILS.PY
# ============================================================================